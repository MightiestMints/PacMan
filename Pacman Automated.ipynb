{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pacman in Automation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authors**: \n",
    "* Corey Craddock - \n",
    "* Braden Hogan -\n",
    "* Justin Rentie - _jurentie@rams.colostate.edu_\n",
    "* Wesley Turner - \n",
    "\n",
    "**Date Submitted**: 12/12/2017\n",
    "\n",
    "**Description**: Create a game of Pacman with controls to vary levels of Pacman and Ghost intelligence and mazes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our CS 440 Final Project, we chose to implement artificial intelligence algorithms that we learned in class throughout this semester to run the classic arcade game Pacman in full automation. We chose this as our final project for multiple reasons.\n",
    "\n",
    "First, all four of us have deeply enjoyed learning artificial intelligence using games this semester, and we wanted our last project to reflect this. \n",
    "\n",
    "Second, we have already seen the AI algorithms, which are Iterative Deepening Search and Q Table Reinforcement Learning, implemented within a game setting. We expected that implementing these algorithms for a new game to be both an obtainable goal, as well as a challenging one.\n",
    "\n",
    "Last, in our initial research for this project, we found that implementing artificial intelligence with Pacman was a common project for computer scientists, taking the form of a rite of a passage for anyone deeply interested in artificial intelligence.\n",
    "\n",
    "Over the course of the last few weeks, we have worked diligently to implement a game of Pacman with these algorithms. Below, we discuss our implementation for the framework of the project, the object used to save the state and players, the Iterative Deepening Search algorithm with Pacman and Ghosts, and the Reinforcement Learning algorithm with Pacman."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "* **[Framework - Corey Craddock](#Framework---Corey-Craddock)**\n",
    "* **[Gameboard - Braden Hogan](#Gameboard---Braden-Hogan)\n",
    "* [Iterative Deepening Search - Justin Rentie](#Iterative-Deepening-Search---Justin-Rentie)\n",
    "* [Reinforcement Learning - Wesley Turner](#Reinforcement-Learning---Wesley-Turner)\n",
    "* [Methods](#Methods)\n",
    "* [Results - Corey Craddock](#Results---Corey-Craddock)\n",
    "* [References](#References)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've outlined thoughts on design and decisions that we made in implementing each of these sections here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Framework - Corey Craddock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pacman and ghosts are both represented by classes we created. Using examples from past lectures, each of these objects has the following base methods:\n",
    "\n",
    "takeAction(board, action) - Returns the state if action is taken on board\n",
    "\n",
    "actions(board) - Returns all possible actions (up, down, left, right)\n",
    "\n",
    "They also contain useful information such as lives, current location, and respawn points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful class created is PlayGame.py. This is what we use to run a game. Its definition is below, with examples used farther down in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def startGame(board, p, ghostsAvailable, Q, intelligenceLevel=3, pacmanIntelligent=False, verbose=True):\n",
    "    # Current Score of the game stored as an Integer\n",
    "    score = 0\n",
    "    turn = 1\n",
    "    dead = False\n",
    "    ghosts = []\n",
    "\n",
    "    while not p.gameOver(board):\n",
    "        beginGhosts = copy.deepcopy(ghostsAvailable)\n",
    "        if dead:\n",
    "            if verbose:\n",
    "                print(\"You died!\")\n",
    "            dead = False\n",
    "        if verbose:\n",
    "            print(\"Lives:\", p.getLives(), \"\\tDots left:\", board.dotsLeft, \"\\tLocation:\", p.location, \"\\tTurn:\", turn, \"\\tScore:\", score)\n",
    "            print(board, end='')\n",
    "            print(\"\\nActions available:\", p.actions(board))\n",
    "        turn, ghosts, p, board, score, dead = runSingleTurn(turn, ghosts, beginGhosts, intelligenceLevel, p, board, score, dead, \"\", pacmanIntelligent, Q)\n",
    "    # Game over\n",
    "    if verbose:\n",
    "        if p.lives == 0:\n",
    "            print(\"Game over: You died!\")\n",
    "        else:\n",
    "            print(\"Game over: You ate all the dots with\", p.getLives(), \"lives left!\")\n",
    "    return (turn, score, p.getLives(), board.dotsLeft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, the end results are very important. In order to speed up testing a wide variety of new board states, we created a seperate class, Stats.py. Stats has a method for every board used, and simply calling the method from main, will run a game on that board. In order to get a wide variety of states tested, we decided to collect results for the following:\n",
    "\n",
    " - 3 different boards\n",
    " - Each board tested with 1, 2 and 3 ghosts\n",
    " - Each (board, ghost) combo tested with ghost intelligence levels of 1, 2 and 3 \n",
    "         - 1: ghosts use shortest distance to hunt Pacman\n",
    "         - 2 and 3: ghosts hunt for Pacman using IDS depths 4 and 8, respectively\n",
    " - Each (board, ghost, intelligence) combo tested with both IDS and Q Table for Pacman's AI\n",
    " \n",
    " The results are at the bottom of the page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gameboard - Braden Hogan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction\n",
    "\n",
    "The design and implementation of gameboard was to approach the problem in an object oriented modular way. The result was a representation of state that could be implemented with any underlying data structure.\n",
    "\n",
    "#### Resources\n",
    "\n",
    "We used the Python documentation to understand and make use of the operator overloading provided within the python language.\n",
    "\n",
    "#### Implementation\n",
    "\n",
    "Within the implementation of BoardGame the important methods are: `move`, `__getitem__`, `__str__`. These functions are designed to control the interactions of other portions of the code with the state representation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `move` implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def move(self, target, x, y):\n",
    "        tarX = target.location[0]\n",
    "        tarY = target.location[1]\n",
    "        if isinstance(target, P.PacMan):\n",
    "            if self.board[x][y] is '.':\n",
    "             self.dotsLeft = self.dotsLeft - 1\n",
    "             self.removeDot(x, y)\n",
    "             self.board[x][y] = 'p'\n",
    "             self.board[tarX][tarY] = ' '\n",
    "             target.location = x,y\n",
    "            else:\n",
    "             self.board[x][y] = 'p'\n",
    "             self.board[tarX][tarY] = ' '\n",
    "             target.location = x,y\n",
    "        else:\n",
    "            if self.board[x][y] is '.':\n",
    "             self.board[x][y] = 'g'\n",
    "             if target.onDot:\n",
    "                 self.board[tarX][tarY] = '.'\n",
    "                 target.onDot = False\n",
    "             else: self.board[tarX][tarY] = ' '\n",
    "             target.onDot = True\n",
    "             target.location = x,y\n",
    "            else:\n",
    "             self.board[x][y] = 'g'\n",
    "             if target.onDot:\n",
    "                 self.board[tarX][tarY] = '.'\n",
    "                 target.onDot = False\n",
    "             else: self.board[tarX][tarY] = ' '\n",
    "             target.location = x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this implementation of the state the first major problem was how other entities would interact with the state. The first interaction was one of the entities needing to move. Within the implementation there were two cases since there were two major entities within the program, pacman and ghost. The only changes made to the state occur through this method which is used within `takeaction` for both ghost and pacman. The details of implementation for each entity is as follows:\n",
    "\n",
    "- Pacman: If the object was a pacman then there were two cases if there was a dot or not. If there was a dot then the number of dots left was decremented and pacman was moved and had the location updated. Otherwise pacman moved and left a blank space behind.\n",
    "\n",
    "\n",
    "- Ghost: This implementation was slightly more complicated since ghosts do not consume dots. Thus the only adjustment from the pacman move was an addition of a Boolean to tell the ghost whether or not to replace its previous position with a dot.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `__getitem__` implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def __getitem__(self, item):\n",
    "        x = item[0]\n",
    "        y = item[1]\n",
    "        return self.board[x][y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access was the second major problem for objects when interacting with the state. The decision was made to implement the assessor operator to act on a tuple of the (x,y) pair wanting to be accessed. Within the logic of the program it was decided as well that since lists were used for the base logic that (0,0) would represent the top left of the current maze. This method controlled the access of the underlying state representation by returning the value at the given (x,y) tuple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `__str__` implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def __str__(self):\n",
    "        value = ''\n",
    "        for i in range(len(self.board)):\n",
    "             for j in range(len(self.board[i])):\n",
    "                value += self.board[i][j]\n",
    "             value += '\\n'\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next important portion of the implementation was printing the board's current state in a clean and efficient way. The decision was made to use the to string method for the `GameBoard` object. This was used since it allowed the state to be printed easily using python's print method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary:\n",
    "\n",
    "Overall the goal was a completed implementation where the state was modularized enough that the underlying representation could be changed without the remainder of the program needing to be updated or modified. Using the modularity created the state could be represented by a numpy array or as a dictionary with changes to only the GameBoard class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Deepening Search - Justin Rentie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Overview:\n",
    "It was our intention in designing our Pacman project that we would implement two different kinds of Artificial Intelligence for PacMan. We wanted to implement Iterative-Deepening Search for the first.\n",
    "\n",
    "##### Resources:\n",
    "We referenced a couple lecture notes from class in implementing IDS for Pacman. We used Lecture 05 Iterative Deepening and Other Uninformed Search Methods and 06 Python Implementation of Iterative Deepening as an example of how to implement basic IDS for searching through a tree of possible states. We also relied on examples from Assignment 02.  \n",
    "\n",
    "_Links to these references are found [below](#References)._\n",
    "\n",
    "##### Implementation:\n",
    "We used Iterative Deepening Search to search within a given depth limit from possible actions that can be taken from pacman at any given state. If pacman locates a dot within the given depth limit the path to that dot is returned. \n",
    "\n",
    "The only major change that needed to be implemented was in the case of approaching a dot near any ghosts. In this situation we added a function called `fearFactor()` which will return `run` from `depthLimitedSearch()` which then in turn calls a function which removes possible moves from Pacman that could lead him towards a ghost. This results in Pacman effectively \"running away\" from the ghosts. \n",
    "\n",
    "This will go on until Pacman finds a dot within the given depth limit that is not in the direction of a ghost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # PacMan \"blood hunter\" AI. Copied from Ghost.\n",
    "    # Helps Intelligent Move in finding the best direction to take to get to nearest dot\n",
    "    def depthLimitedSearch(self, board, ghosts, closestDots, actions, takeAction, depthLimit):\n",
    "        if PacMan.fearFactor(self, ghosts):\n",
    "            return 'run'\n",
    "\n",
    "        for dot in closestDots:\n",
    "            if self.location == dot.location:\n",
    "                return []\n",
    "\n",
    "        if depthLimit == 0:\n",
    "            return \"cutoff\"\n",
    "\n",
    "        cutOffOccurred = False\n",
    "        for action in PacMan.actions(self, board):\n",
    "            copyBoard = copy.deepcopy(board)\n",
    "            copySelf = copy.deepcopy(self)\n",
    "            takeAction(copySelf, copyBoard, action)\n",
    "            result = PacMan.depthLimitedSearch(copySelf, copyBoard, ghosts, closestDots, actions, takeAction,\n",
    "                                              depthLimit - 1)\n",
    "\n",
    "            if result is \"cutoff\":\n",
    "                cutOffOccurred = True\n",
    "            elif result is not \"failure\":\n",
    "                return action\n",
    "        if cutOffOccurred:\n",
    "            return \"cutoff\"\n",
    "        else:\n",
    "            return \"failure\"\n",
    "\n",
    "    # Causes the ghost to scan through the board, making the most intelligent shortest path decision\n",
    "    def intelligentMove(self, board, ghosts, maxDepth=4):\n",
    "        closestDots = PacMan.getClosestDots(self, board)\n",
    "\n",
    "        for dot in closestDots:\n",
    "            if self.location == dot.location:\n",
    "                return\n",
    "\n",
    "        for depth in range(maxDepth):\n",
    "            result = PacMan.depthLimitedSearch(self, board, ghosts, closestDots, PacMan.actions, PacMan.takeAction,\n",
    "                                              depth)\n",
    "            if result != \"cutoff\" and result != \"failure\" and result != 'run':\n",
    "                print(\"PacMan found intelligent move. Returning intelligentMove\")\n",
    "                return PacMan.takeAction(self, board, result)\n",
    "\n",
    "        if(result == 'run'):\n",
    "            PacMan.runFromGhost(self, board, ghosts,  PacMan.actions)\n",
    "        else:\n",
    "            PacMan.makeRandomMove(self, board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example run of Pacman using Iterative-Deepening Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import PlayGame as game\n",
    "import PacMan as P\n",
    "import Ghost as G\n",
    "import Dot as d\n",
    "import GameBoard as Board\n",
    "import copy as copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # Really basic state to start with\n",
    "state = [['=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '='],\n",
    "        ['|', ' ', ' ', ' ', ' ', 'G', ' ', ' ', ' ', ' ', '|'],\n",
    "        ['|', ' ', '=', '=', '=', ' ', '=', '=', '=', ' ', '|'],\n",
    "        ['|', ' ', '|', ' ', '|', ' ', '|', ' ', '|', ' ', '|'],\n",
    "        ['|', ' ', '=', '=', '=', ' ', '=', '=', '=', ' ', '|'],\n",
    "        ['|', '.', '.', '.', '.', '.', '.', '.', '.', 'P', '|'],\n",
    "        ['=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lives: 3 \tDots left: 8 \tLocation: (5, 9) \tTurn: 1 \tScore: 0\n",
      "===========\n",
      "|    G    |\n",
      "| === === |\n",
      "| | | | | |\n",
      "| === === |\n",
      "|........P|\n",
      "===========\n",
      "\n",
      "Actions available: ['up', 'left']\n",
      "PacMan found intelligent move. Returning intelligentMove\n",
      "Lives: 3 \tDots left: 7 \tLocation: (5, 8) \tTurn: 2 \tScore: 10\n",
      "===========\n",
      "|    G    |\n",
      "| === === |\n",
      "| | | | | |\n",
      "| === === |\n",
      "|.......p |\n",
      "===========\n",
      "\n",
      "Actions available: ['left', 'right']\n",
      "PacMan found intelligent move. Returning intelligentMove\n",
      "Lives: 3 \tDots left: 6 \tLocation: (5, 7) \tTurn: 3 \tScore: 19\n",
      "===========\n",
      "|    G    |\n",
      "| === === |\n",
      "| | | | | |\n",
      "| === === |\n",
      "|......p  |\n",
      "===========\n",
      "\n",
      "Actions available: ['left', 'right']\n",
      "PacMan found intelligent move. Returning intelligentMove\n",
      "Lives: 3 \tDots left: 5 \tLocation: (5, 6) \tTurn: 4 \tScore: 28\n",
      "===========\n",
      "|         |\n",
      "| ===g=== |\n",
      "| | | | | |\n",
      "| === === |\n",
      "|.....p   |\n",
      "===========\n",
      "\n",
      "Actions available: ['left', 'right']\n",
      "PacMan found intelligent move. Returning intelligentMove\n",
      "Lives: 3 \tDots left: 4 \tLocation: (5, 5) \tTurn: 5 \tScore: 37\n",
      "===========\n",
      "|         |\n",
      "| === === |\n",
      "| | |g| | |\n",
      "| === === |\n",
      "|....p    |\n",
      "===========\n",
      "\n",
      "Actions available: ['up', 'left', 'right']\n",
      "running from ghosts\n",
      "Lives: 3 \tDots left: 3 \tLocation: (5, 4) \tTurn: 6 \tScore: 46\n",
      "===========\n",
      "|         |\n",
      "| === === |\n",
      "| | | | | |\n",
      "| ===g=== |\n",
      "|...p     |\n",
      "===========\n",
      "\n",
      "Actions available: ['left', 'right']\n",
      "running from ghosts\n",
      "Lives: 3 \tDots left: 2 \tLocation: (5, 3) \tTurn: 7 \tScore: 55\n",
      "===========\n",
      "|         |\n",
      "| === === |\n",
      "| | | | | |\n",
      "| === === |\n",
      "|..p g    |\n",
      "===========\n",
      "\n",
      "Actions available: ['left', 'right']\n",
      "running from ghosts\n",
      "Lives: 3 \tDots left: 1 \tLocation: (5, 2) \tTurn: 8 \tScore: 64\n",
      "===========\n",
      "|         |\n",
      "| === === |\n",
      "| | | | | |\n",
      "| === === |\n",
      "|.p g     |\n",
      "===========\n",
      "\n",
      "Actions available: ['left', 'right']\n",
      "running from ghosts\n",
      "Game over: You ate all the dots with 3 lives left!\n"
     ]
    }
   ],
   "source": [
    "# Start game with above state and 2 ghosts\n",
    "board = Board.GameBoard(state)\n",
    "# Create a Pacman object using this board\n",
    "p = P.PacMan(board.pacManSpawnPt)\n",
    "\n",
    "ghostsAvailable = [G.Ghost(board.ghostSpawnPt)]\n",
    "intelligenceLevel = 3\n",
    "\n",
    "# Initialize Q to empty array\n",
    "Q = []\n",
    "\n",
    "# Runs startGame with Q table and printing\n",
    "game.startGame(board, p, ghostsAvailable, Q, intelligenceLevel, True, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning - Wesley Turner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Overview:\n",
    "From the beginning, we knew we wanted to write a function to train a Q table for the states that Pacman would most likely move through in a game. We planned for this to be our most optimized form of a smart Pacman, as this intelligence made the most sense for our game.\n",
    "\n",
    "##### Resources:\n",
    "We utilized two different sources to implement this. The first was from a previous assignment in this course, Assignment 5. A link for this assignment page can be found below. This assignment had students implement training a Q table and testing it with the Towers of Hanoi puzzle. Although this was a good start, that puzzle is a one-person game, so our reinforcement would need to differ vastly. However, the overall structure and design for the trainQ function initially came from this assignment.\n",
    "\n",
    "Secondly, we took inspiration for the reinforcement for Pacman from the lecture notes titled “Reinforcement Learning for Two-Player Games”. We knew we needed to augment the reinforcement for different actions that Pacman may take, and the implementation in this lecture was sufficient to start our brainstorming.\n",
    "\n",
    "_Links to these references are found [below](#References)._\n",
    "\n",
    "##### Implementation:\n",
    "Despite these sources aiding us with design, we were still running into issues with what actions needed reinforcement. These were the actions we knew we could reinforce:\n",
    "\n",
    " - Change to score\n",
    " - Pacman dies\n",
    " - Pacman wins or loses\n",
    " - Pacman eats a dot\n",
    "\n",
    "We tried a variety of combinations of these reinforcements. For the most part, these were blind tests: which combination of reinforcements would lead Pacman to have the best and fastest results? We ended up utilizing the implementation below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def trainQ(self, board, nRepetitions, learningRate, epsilonDecayFactor, ghostsAvailable, intelligenceLevel, verbose=False):\n",
    "        maxGames = nRepetitions\n",
    "        rho = learningRate\n",
    "        epsilonDecayRate = epsilonDecayFactor\n",
    "        epsilon = 1.0\n",
    "        Q = {}\n",
    "        scores = []\n",
    "\n",
    "        for nGames in range(maxGames):\n",
    "            if verbose:\n",
    "                print(\"Game:\", nGames, \"; Starting game.\")\n",
    "            epsilon *= epsilonDecayRate\n",
    "            step = 0\n",
    "            state = copy.deepcopy(board)\n",
    "            copySelf = copy.deepcopy(self)\n",
    "            ghosts = []\n",
    "            score = 0\n",
    "            done = False\n",
    "\n",
    "            while not done and not copySelf.gameOver(state):\n",
    "                dead = False\n",
    "                copyGhosts = copy.deepcopy(ghostsAvailable)\n",
    "                step += 1\n",
    "                copyState = copy.deepcopy(state)\n",
    "                move = PacMan.epsilonGreedy(copySelf, epsilon, Q, copyState)\n",
    "\n",
    "                _, ghosts, copySelf, stateNew, score, dead = PlayGame.runSingleTurn(step, ghosts, copyGhosts, intelligenceLevel, copySelf, copyState, score, dead, move)\n",
    "                # Full return: turn, ghosts, p, board, score, dead\n",
    "\n",
    "                #Initial value\n",
    "                if PacMan.boardMoveTuple(copySelf, state, move) not in Q:\n",
    "                    Q[PacMan.boardMoveTuple(copySelf, state, move)] = 0  # initial Q value for new state,move\n",
    "\n",
    "                if stateNew.dotsLeft < state.dotsLeft:\n",
    "                    #Pacman ate a dot. Medium positive reinforcement\n",
    "                    Q[PacMan.boardMoveTuple(copySelf, state, move)] += 3\n",
    "                else:\n",
    "                    #Pacman did not eat a dot. Small negative reinforcement\n",
    "                    Q[PacMan.boardMoveTuple(copySelf, state, move)] += -1\n",
    "                if dead:\n",
    "                    #Pacman lost a life. Large negative reinforcement\n",
    "                    Q[PacMan.boardMoveTuple(copySelf, state, move)] = -10\n",
    "\n",
    "                if step > 1:\n",
    "                    Q[PacMan.boardMoveTuple(copySelf, stateOld, moveOld)] += rho * (Q[PacMan.boardMoveTuple(copySelf, state, move)] - Q[PacMan.boardMoveTuple(copySelf, stateOld, moveOld)])\n",
    "\n",
    "                stateOld, moveOld, scoreOld = state, move, score\n",
    "                state = stateNew\n",
    "            if verbose:\n",
    "                if copySelf.lives > 0:\n",
    "                    print(\"Pacman Won!\")\n",
    "                else:\n",
    "                    print(\"Pacman Lost!\")\n",
    "            scores.append(score)\n",
    "        return Q, scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This combination of reinforcements were tested to have the best results for Pacman, as it allows him to have some flexibility when choosing a state/move that is not necessarily taking the closest path to a dot (i.e. he needs to run away). We will be displaying the performance that we found in using trainQ and the Q table it creates in a section below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example run of Pacman using training Q table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import PlayGame as game\n",
    "import PacMan as P\n",
    "import Ghost as G\n",
    "import Dot as d\n",
    "import GameBoard as Board\n",
    "import copy as copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # Really basic state to start with\n",
    "state = [['=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '='],\n",
    "        ['|', ' ', ' ', ' ', ' ', 'G', ' ', ' ', ' ', ' ', '|'],\n",
    "        ['|', ' ', '=', '=', '=', ' ', '=', '=', '=', ' ', '|'],\n",
    "        ['|', ' ', '|', ' ', '|', ' ', '|', ' ', '|', ' ', '|'],\n",
    "        ['|', ' ', '=', '=', '=', ' ', '=', '=', '=', ' ', '|'],\n",
    "        ['|', '.', '.', '.', '.', '.', '.', '.', '.', 'P', '|'],\n",
    "        ['=', '=', '=', '=', '=', '=', '=', '=', '=', '=', '=']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game: 0 ; Starting game.\n",
      "Pacman Lost!\n",
      "Game: 1 ; Starting game.\n",
      "Pacman Lost!\n",
      "Game: 2 ; Starting game.\n",
      "Pacman Lost!\n",
      "Game: 3 ; Starting game.\n",
      "Pacman Lost!\n",
      "Game: 4 ; Starting game.\n",
      "Pacman Lost!\n",
      "Game: 5 ; Starting game.\n",
      "Pacman Lost!\n",
      "Game: 6 ; Starting game.\n",
      "Pacman Lost!\n",
      "Game: 7 ; Starting game.\n",
      "Pacman Lost!\n",
      "Game: 8 ; Starting game.\n",
      "Pacman Won!\n",
      "Game: 9 ; Starting game.\n",
      "Pacman Won!\n",
      "Game: 10 ; Starting game.\n",
      "Pacman Won!\n",
      "Game: 11 ; Starting game.\n",
      "Pacman Won!\n",
      "Game: 12 ; Starting game.\n",
      "Pacman Won!\n",
      "Game: 13 ; Starting game.\n",
      "Pacman Won!\n",
      "Game: 14 ; Starting game.\n",
      "Pacman Won!\n",
      "Game: 15 ; Starting game.\n",
      "Pacman Won!\n",
      "Game: 16 ; Starting game.\n",
      "Pacman Won!\n",
      "Game: 17 ; Starting game.\n",
      "Pacman Won!\n",
      "Game: 18 ; Starting game.\n",
      "Pacman Won!\n",
      "Game: 19 ; Starting game.\n",
      "Pacman Won!\n",
      "Game: 20 ; Starting game.\n",
      "Pacman Won!\n",
      "Game: 21 ; Starting game.\n",
      "Pacman Won!\n",
      "Game: 22 ; Starting game.\n",
      "Pacman Won!\n",
      "Game: 23 ; Starting game.\n",
      "Pacman Won!\n",
      "Game: 24 ; Starting game.\n",
      "Pacman Won!\n",
      "Game: 25 ; Starting game.\n",
      "Pacman Won!\n",
      "Game: 26 ; Starting game.\n",
      "Pacman Won!\n",
      "Game: 27 ; Starting game.\n",
      "Pacman Won!\n",
      "Game: 28 ; Starting game.\n",
      "Pacman Won!\n",
      "Game: 29 ; Starting game.\n",
      "Pacman Won!\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73]\n",
      "Lives: 3 \tDots left: 8 \tLocation: (5, 9) \tTurn: 1 \tScore: 0\n",
      "===========\n",
      "|    G    |\n",
      "| === === |\n",
      "| | | | | |\n",
      "| === === |\n",
      "|........P|\n",
      "===========\n",
      "\n",
      "Actions available: ['up', 'left']\n",
      "Lives: 3 \tDots left: 7 \tLocation: (5, 8) \tTurn: 2 \tScore: 10\n",
      "===========\n",
      "|    G    |\n",
      "| === === |\n",
      "| | | | | |\n",
      "| === === |\n",
      "|.......p |\n",
      "===========\n",
      "\n",
      "Actions available: ['left', 'right']\n",
      "Lives: 3 \tDots left: 6 \tLocation: (5, 7) \tTurn: 3 \tScore: 19\n",
      "===========\n",
      "|    G    |\n",
      "| === === |\n",
      "| | | | | |\n",
      "| === === |\n",
      "|......p  |\n",
      "===========\n",
      "\n",
      "Actions available: ['left', 'right']\n",
      "Lives: 3 \tDots left: 5 \tLocation: (5, 6) \tTurn: 4 \tScore: 28\n",
      "===========\n",
      "|         |\n",
      "| ===g=== |\n",
      "| | | | | |\n",
      "| === === |\n",
      "|.....p   |\n",
      "===========\n",
      "\n",
      "Actions available: ['left', 'right']\n",
      "Lives: 3 \tDots left: 4 \tLocation: (5, 5) \tTurn: 5 \tScore: 37\n",
      "===========\n",
      "|         |\n",
      "| === === |\n",
      "| | |g| | |\n",
      "| === === |\n",
      "|....p    |\n",
      "===========\n",
      "\n",
      "Actions available: ['up', 'left', 'right']\n",
      "Lives: 3 \tDots left: 3 \tLocation: (5, 4) \tTurn: 6 \tScore: 46\n",
      "===========\n",
      "|         |\n",
      "| === === |\n",
      "| | | | | |\n",
      "| ===g=== |\n",
      "|...p     |\n",
      "===========\n",
      "\n",
      "Actions available: ['left', 'right']\n",
      "Lives: 3 \tDots left: 2 \tLocation: (5, 3) \tTurn: 7 \tScore: 55\n",
      "===========\n",
      "|         |\n",
      "| === === |\n",
      "| | | | | |\n",
      "| === === |\n",
      "|..p g    |\n",
      "===========\n",
      "\n",
      "Actions available: ['left', 'right']\n",
      "Lives: 3 \tDots left: 1 \tLocation: (5, 2) \tTurn: 8 \tScore: 64\n",
      "===========\n",
      "|         |\n",
      "| === === |\n",
      "| | | | | |\n",
      "| === === |\n",
      "|.p g     |\n",
      "===========\n",
      "\n",
      "Actions available: ['left', 'right']\n",
      "Game over: You ate all the dots with 3 lives left!\n"
     ]
    }
   ],
   "source": [
    "# Start game with above state and 2 ghosts\n",
    "board = Board.GameBoard(state)\n",
    "# Create a Pacman object using this board\n",
    "p = P.PacMan(board.pacManSpawnPt)\n",
    "\n",
    "ghostsAvailable = [G.Ghost(board.ghostSpawnPt)]\n",
    "intelligenceLevel = 3\n",
    "\n",
    "# Train Q for p\n",
    "Q = []\n",
    "# Trains Q table and prints each game\n",
    "Q, scores = p.trainQ(board, 30, 0.5, 0.7, ghostsAvailable, intelligenceLevel, True)\n",
    "print(scores)\n",
    "\n",
    "# Runs startGame with Q table and printing\n",
    "game.startGame(board, p, ghostsAvailable, Q, intelligenceLevel, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are all methods and files in our project. We've decided to show who authored which section to show that we all worked as evenly as possible in implementing this project.\n",
    " \n",
    " - **Dot.py** - All methods authored by Justin Rentie\n",
    " - **GameBoard.py** - All methods authored by Braden Hogan\n",
    " - **Ghost.py**\n",
    "     - init - Corey Craddock & Justin Rentie\n",
    "     - actions - Corey Craddock & Braden Hogan\n",
    "     - takeAction - Corey Craddock, Braden Hogan, & Justin Rentie\n",
    "     - randomMove - Corey Craddock\n",
    "     - takeActionShortestDistance - Wesley Turner\n",
    "     - depthLimitedSearch - Wesley Turner\n",
    "     - intelligentMove - Wesley Turner\n",
    " - **Pacman.py**\n",
    "     - init - Corey Craddock & Justin Rentie\n",
    "     - spawnPt - Corey Craddock\n",
    "     - actions - Corey Craddock & Braden Hogan\n",
    "     - takeAction - Corey Craddock, Braden Hogan, & Justin Rentie\n",
    "     - calculateDistance - Justin Rentie\n",
    "     - getClosestDot - Justin Rentie\n",
    "     - directionToObj - Justin Rentie\n",
    "     - fearFactor - Justin Rentie\n",
    "     - depthLimitedSearch - Justin Rentie\n",
    "     - intelligentMove - Justin Rentie\n",
    "     - runFromGhost - Justin Rentie\n",
    "     - makeRandomMove - Justin Rentie\n",
    "     - gameOver - Corey Craddock\n",
    "     - getLives - Corey Craddock\n",
    "     - boardMoveTuple - Wesley Turner\n",
    "     - useReinforcementTable - Wesley Turner\n",
    "     - epsilonGreedy - Wesley Turner\n",
    "     - trainQ - Wesley Turner\n",
    " - **PlayGame.py**\n",
    "     - getDots - Justin Rentie\n",
    "     - runSingleTurn - Wesley Turner\n",
    "     - startGame - Corey Craddock & Wesley Turner\n",
    "     - main - Corey Craddock & Wesley Turner\n",
    " - **Stats.py** - All meothods authored by Corey Craddock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results - Corey Craddock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test our Pacman AI algorithms on a wide variety of states, we created a seperate class **Stats.py** to create multiple boards and run both the IDS and Q Table AI algorithms on each board, with a variety of ghosts and ghost intelligence levels. Here are our results. ** Warning: Running any of the code cells below will take 10-30 minutes to complete. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "** Board 1 **\n",
    "\n",
    "First, we will start with a simple state, with a clear path. The state looks like this: ![this](board1.png \"Board 1\")\n",
    "\n",
    "The Ghost on the board is the ghost spawn point, and the Pacman is the Pacman spawn point. We used an ASCII representation of the board as our visual during the project bulding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this board, lets see how Pacman does with varying number of ghosts and varying ghost intelligence. We will try both of Pacman's AI algorithms on this board with 1-3 ghosts, each with a 1-3 intelligence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board 1:\n",
      "===========\n",
      "|    G    |\n",
      "| === === |\n",
      "| | | | | |\n",
      "| === === |\n",
      "|........P|\n",
      "===========\n",
      "\n",
      "\t [1, 1] IDS 30-average results:\t\tTurns: 17 \tScore: 64 \tLives left: 3 \tDots left: 0\n",
      "\t [1, 1] Q Table Results:\t\tTurns: 9 \tScore: 73 \tLives left: 3 \tDots left: 0\n",
      "\t [1, 2] IDS 30-average results:\t\tTurns: 21 \tScore: 62 \tLives left: 3 \tDots left: 0\n",
      "\t [1, 2] Q Table Results:\t\tTurns: 9 \tScore: 73 \tLives left: 3 \tDots left: 0\n",
      "\t [1, 3] IDS 30-average results:\t\tTurns: 18 \tScore: 63 \tLives left: 3 \tDots left: 0\n",
      "\t [1, 3] Q Table Results:\t\tTurns: 9 \tScore: 73 \tLives left: 3 \tDots left: 0\n",
      "\t [2, 1] IDS 30-average results:\t\tTurns: 21 \tScore: 43 \tLives left: 1 \tDots left: 1\n",
      "\t [2, 1] Q Table Results:\t\tTurns: 9 \tScore: 73 \tLives left: 3 \tDots left: 0\n",
      "\t [2, 2] IDS 30-average results:\t\tTurns: 22 \tScore: 41 \tLives left: 1 \tDots left: 1\n",
      "\t [2, 2] Q Table Results:\t\tTurns: 9 \tScore: 73 \tLives left: 3 \tDots left: 0\n",
      "\t [2, 3] IDS 30-average results:\t\tTurns: 19 \tScore: 62 \tLives left: 3 \tDots left: 0\n",
      "\t [2, 3] Q Table Results:\t\tTurns: 9 \tScore: 73 \tLives left: 3 \tDots left: 0\n",
      "\t [3, 1] IDS 30-average results:\t\tTurns: 19 \tScore: 36 \tLives left: 1 \tDots left: 2\n",
      "\t [3, 1] Q Table Results:\t\tTurns: 9 \tScore: 73 \tLives left: 3 \tDots left: 0\n",
      "\t [3, 2] IDS 30-average results:\t\tTurns: 19 \tScore: 34 \tLives left: 1 \tDots left: 2\n",
      "\t [3, 2] Q Table Results:\t\tTurns: 9 \tScore: 73 \tLives left: 3 \tDots left: 0\n",
      "\t [3, 3] IDS 30-average results:\t\tTurns: 19 \tScore: 36 \tLives left: 1 \tDots left: 2\n",
      "\t [3, 3] Q Table Results:\t\tTurns: 9 \tScore: 73 \tLives left: 3 \tDots left: 0\n"
     ]
    }
   ],
   "source": [
    "# Format: [<number of ghosts>, <ghost intelligence>] <pacMan AI>  <turns>  <score>  <lives left>  <moves explored>  <dots left>\n",
    "import Stats as stats\n",
    "print(\"Board 1:\")\n",
    "for i in range(1, 4):\n",
    "    for j in range(1, 4):\n",
    "        if i is 1 and j is 1:\n",
    "            stats.board1(i, j, True, True)\n",
    "        else:\n",
    "            stats.board1(i, j, True, False)\n",
    "        stats.board1(i, j, False, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some graphs to help visualize the data above: ![this](board1Graphs.png \"Board 1 Graphs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code ran the board 9 times. Each turn it switched off between IDS (30 game average) and Q Table (trained 30 times) and increased the number of ghosts and their intelligence. From these results, we can see that with this board, Q Table performs better in every area. It always eats all the dots in 9 turns without losing any lives. IDS doesn't perform quite as well, but still mostly completes the board. The ghost intelligence doesn't seem to affect IDS very much, but the  number of ghosts have a big impact. As you add ghosts, the IDS algorithm takes more turns to complete, loses more lives, and has a lower score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "** Board 2 **\n",
    "\n",
    "Now we will try a new board, and see how that affects Pacman's performance. We quickly learned that increasing the boards size  drastically increases the time the Q Table completes. One board that we tried, we let the algorithms run for around ~6 hours overnight and they did not complete. Because of this restriction, the board size and structure will stay the same, but we will add new dots in different positions with future boards. I'm also limiting the number of ghosts on the third board to only 2 ghosts. The second board looks like this:![this](board2.png \"Board 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had to break up the testing into several cells here, as running them in the same cell takes a very long time to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board 2:\n",
      "===========\n",
      "|.   G   .|\n",
      "|.=== ===.|\n",
      "|.| | | |.|\n",
      "|.=== ===.|\n",
      "|........P|\n",
      "===========\n",
      "\n",
      "\t [1, 1] IDS 30-average results:\t\tTurns: 32 \tScore: 129 \tLives left: 3 \tDots left: 0\n",
      "\t [1, 1] Q Table Results:\t\tTurns: 21 \tScore: 141 \tLives left: 3 \tDots left: 0\n",
      "\t [1, 2] IDS 30-average results:\t\tTurns: 31 \tScore: 130 \tLives left: 3 \tDots left: 0\n",
      "\t [1, 2] Q Table Results:\t\tTurns: 48 \tScore: 0 \tLives left: 0 \tDots left: 10\n"
     ]
    }
   ],
   "source": [
    "# Format: [<number of ghosts>, <ghost intelligence>] <pacMan AI>  <turns>  <score>  <lives left>  <moves explored>  <dots left>\n",
    "import Stats as stats\n",
    "print(\"Board 2:\")\n",
    "stats.board2(1, 1, True, True)\n",
    "stats.board2(1, 1, False, False)\n",
    "stats.board2(1, 2, True, False)\n",
    "stats.board2(1, 2, False, False)\n",
    "print('', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [1, 3] IDS 30-average results:\t\tTurns: 25 \tScore: 136 \tLives left: 3 \tDots left: 0\n",
      "\t [1, 3] Q Table Results:\t\tTurns: 33 \tScore: 29 \tLives left: 2 \tDots left: 0\n",
      "\t [2, 1] IDS 30-average results:\t\tTurns: 32 \tScore: 43 \tLives left: 1 \tDots left: 6\n",
      "\t [2, 1] Q Table Results:\t\tTurns: 19 \tScore: 0 \tLives left: 0 \tDots left: 8\n"
     ]
    }
   ],
   "source": [
    "stats.board2(1, 3, True, False)\n",
    "stats.board2(1, 3, False, False)\n",
    "stats.board2(2, 1, True, False)\n",
    "stats.board2(2, 1, False, False)\n",
    "print('', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t [2, 2] IDS 30-average results:\t\tTurns: 32 \tScore: 60 \tLives left: 1 \tDots left: 4\n",
      "\t [2, 2] Q Table Results:\t\tTurns: 49 \tScore: 0 \tLives left: 0 \tDots left: 11\n",
      "\t [2, 3] IDS 30-average results:\t\tTurns: 28 \tScore: 133 \tLives left: 3 \tDots left: 0\n",
      "\t [2, 3] Q Table Results:\t\tTurns: 25 \tScore: 37 \tLives left: 2 \tDots left: 0\n"
     ]
    }
   ],
   "source": [
    "stats.board2(2, 2, True, False)\n",
    "stats.board2(2, 2, False, False)\n",
    "stats.board2(2, 3, True, False)\n",
    "stats.board2(2, 3, False, False)\n",
    "print('', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although I will not call it here due to the high cost, I also collected the data from adding a third ghost. \n",
    "\n",
    "The graphs for Board 2: ![this](board2Graphs.png \"Board 2 Graphs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When adding more dots, we see that Q Table decreases significantly in effectiveness. In fact, there are only 2 times that Q Table completes the board, and one of those times, Pacman still loses a life. IDS does better than Q Table on this board, getting a higher average score, eating more dots, losing less lives. When we add 3 ghosts, each with the highest intelligence, neither IDS or Q Table is able to win"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "** Board 3**\n",
    "\n",
    "Again, we will add and remove some dots and see how our algorithms do in winning the game. Here is our third board: ![this](board3.png \"Board 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Board 3, the Jupyter notebook takes too long to run the tests. I am able to run them on an IDE, with the results below:\n",
    "\n",
    "[1, 1] IDS 30-average results:            Turns: 48        Score: 74        Lives Left: 3        Dots left: 0\n",
    "\n",
    "[1, 1] Q Table results:                   Turns: 45        Score: 0         Lives Left: 0        Dots left: 4\n",
    "\n",
    "[1, 2] IDS 30-average results:            Turns: 40        Score: 81        Lives Left: 3        Dots left: 0\n",
    "\n",
    "[1, 2] Q Table results:                   Turns: 27        Score: 0         Lives Left: 0        Dots left: 7\n",
    "\n",
    "[1, 3] IDS 30-average results:            Turns: 47        Score: 74        Lives Left: 3        Dots left: 0\n",
    "\n",
    "[1, 3] Q Table results:                   Turns: 38        Score: 0         Lives Left: 0        Dots left: 2\n",
    "\n",
    "[2, 1] IDS 30-average results:            Turns: 43        Score: 55        Lives Left: 2        Dots left: 1\n",
    "\n",
    "[2, 1] Q Table results:                   Turns: 24        Score: 0         Lives Left: 0        Dots left: 8\n",
    "\n",
    "[2, 2] IDS 30-average results:            Turns: 69        Score: 38        Lives Left: 1        Dots left: 3\n",
    "\n",
    "[2, 2] Q Table results:                   Turns: 31        Score: 0         Lives Left: 0        Dots left: 2\n",
    "\n",
    "[2, 3] IDS 30-average results:            Turns: 46        Score: 75        Lives Left: 3        Dots left: 0\n",
    "\n",
    "[2, 3] Q Table results:                   Turns: 20        Score: 0         Lives Left: 0        Dots left: 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the visuals: ![this](board3Graphs.png \"Board 3 Graphs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in the last board, IDS outperforms Q Table with this board as well. Q Table is not able to fully complete any game, although it does get close when there is only one ghost. IDS is able to get a relatively high score while not losing all it's lives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Public GitHub Repository Used for Development](https://github.com/StaticNomad/PacMan)\n",
    "* [Lecture 05 - Iterative Deepening and Other Uninformed Search Methods](http://nbviewer.jupyter.org/url/www.cs.colostate.edu/~anderson/cs440/notebooks/05%20Iterative%20Deepening%20and%20Other%20Uninformed%20Search%20Methods.ipynb)\n",
    "* [Lecture 06 - Python Implementation of Iterative Deepening](http://nbviewer.jupyter.org/url/www.cs.colostate.edu/~anderson/cs440/notebooks/06%20Python%20Implementation%20of%20Iterative%20Deepening.ipynb)\n",
    "* [Lecture 15 - Reinforcement Learning for Two-Player Games](http://nbviewer.jupyter.org/url/www.cs.colostate.edu/~anderson/cs440/notebooks/15%20Reinforcement%20Learning%20for%20Two-Player%20Games.ipynb) \n",
    "* [Assignemnt 02 - Iterative-Deepending Search](http://nbviewer.jupyter.org/url/www.cs.colostate.edu/~anderson/cs440/notebooks/A2%20Iterative-Deepening%20Search.ipynb)\n",
    "* [Assignemnt 05 - A5 Reinforcement Learning Solution to the Towers of Hanoi Puzzle](http://nbviewer.jupyter.org/url/www.cs.colostate.edu/~anderson/cs440/notebooks/A5%20Reinforcement%20Learning%20Solution%20to%20Towers%20of%20Hanoi.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
